---
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: monitoring
  labels:
    app: loki
    component: monitoring
    part-of: hcbs-revenue-management
data:
  loki.yaml: |
    auth_enabled: false

    server:
      http_listen_port: 3100
      grpc_listen_port: 9096

    ingester:
      lifecycler:
        address: 127.0.0.1
        ring:
          kvstore:
            store: inmemory
          replication_factor: 1
        final_sleep: 0s
      chunk_idle_period: 1h
      chunk_retain_period: 30s
      max_transfer_retries: 0

    schema_config:
      configs:
        - from: 2020-10-24
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h

    storage_config:
      boltdb_shipper:
        active_index_directory: /data/loki/index
        cache_location: /data/loki/index_cache
        cache_ttl: 24h
        shared_store: filesystem
      filesystem:
        directory: /data/loki/chunks

    compactor:
      working_directory: /data/loki/compactor
      shared_store: filesystem

    limits_config:
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      retention_period: 744h
      enforce_metric_name: false
      ingestion_rate_mb: 10
      ingestion_burst_size_mb: 20

    chunk_store_config:
      max_look_back_period: 744h

    table_manager:
      retention_deletes_enabled: true
      retention_period: 744h

    ruler:
      storage:
        type: local
        local:
          directory: /data/loki/rules
      rule_path: /data/loki/rules
      alertmanager_url: http://alertmanager.monitoring.svc:9093
      ring:
        kvstore:
          store: inmemory
      enable_api: true
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: monitoring
  labels:
    app: promtail
    component: monitoring
    part-of: hcbs-revenue-management
data:
  promtail.yaml: |
    server:
      http_listen_port: 9080
      grpc_listen_port: 0

    positions:
      filename: /tmp/positions.yaml

    clients:
      - url: http://loki.monitoring.svc:3100/loki/api/v1/push

    scrape_configs:
      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_controller_name]
            regex: ([0-9a-z-.]+?)(-[0-9a-f]{8,10})?
            action: replace
            target_label: __tmp_controller_name
          - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name, __meta_kubernetes_pod_label_app, __tmp_controller_name, __meta_kubernetes_pod_name]
            regex: (.*);(.*);(.*);(.*)
            action: replace
            replacement: ${1:-${2:-${3:-$4}}}
            target_label: app
          - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_component, __meta_kubernetes_pod_label_component]
            regex: (.*);(.*)
            action: replace
            replacement: ${1:-$2}
            target_label: component
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - action: replace
            replacement: $1
            separator: /
            source_labels:
              - __meta_kubernetes_namespace
              - app
            target_label: job
          - action: replace
            source_labels:
              - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_name
            target_label: pod
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_container_name
            target_label: container
          - action: replace
            replacement: /var/log/pods/*$1/*.log
            separator: /
            source_labels:
              - __meta_kubernetes_pod_uid
              - __meta_kubernetes_pod_container_name
            target_label: __path__
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_node_name
            target_label: node_name
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_ip
            target_label: pod_ip

      # Specific scrape config for backend services with structured logging
      - job_name: hcbs-backend
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace]
            action: keep
            regex: hcbs
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: hcbs-backend
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - action: replace
            source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - action: replace
            source_labels: [__meta_kubernetes_pod_name]
            target_label: pod
          - action: replace
            source_labels: [__meta_kubernetes_pod_container_name]
            target_label: container
          - action: replace
            replacement: /var/log/pods/*$1/*.log
            separator: /
            source_labels:
              - __meta_kubernetes_pod_uid
              - __meta_kubernetes_pod_container_name
            target_label: __path__
        pipeline_stages:
          - json:
              expressions:
                level: level
                message: message
                timestamp: timestamp
                logger: logger
                trace_id: trace_id
                span_id: span_id
                req_method: req.method
                req_url: req.url
                res_status: res.statusCode
                user_id: user.id
                error: error
          - labels:
              level:
              logger:
              trace_id:
              span_id:
              req_method:
              req_url:
              res_status:
              user_id:
          - timestamp:
              source: timestamp
              format: RFC3339Nano
          - output:
              source: message

      # Specific scrape config for web frontend 
      - job_name: hcbs-web
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace]
            action: keep
            regex: hcbs
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: hcbs-web
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - action: replace
            source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - action: replace
            source_labels: [__meta_kubernetes_pod_name]
            target_label: pod
          - action: replace
            source_labels: [__meta_kubernetes_pod_container_name]
            target_label: container
          - action: replace
            replacement: /var/log/pods/*$1/*.log
            separator: /
            source_labels:
              - __meta_kubernetes_pod_uid
              - __meta_kubernetes_pod_container_name
            target_label: __path__
        pipeline_stages:
          - json:
              expressions:
                level: level
                message: message
                timestamp: timestamp
                page: page
                trace_id: trace_id
                span_id: span_id
                user_id: user.id
                error: error
          - labels:
              level:
              page:
              trace_id:
              span_id:
              user_id:
          - timestamp:
              source: timestamp
              format: RFC3339Nano
          - output:
              source: message
      
      # System-level logs
      - job_name: kubernetes-system
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - action: replace
            source_labels: [__meta_kubernetes_node_name]
            target_label: node_name
        pipeline_stages:
          - docker: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki
  namespace: monitoring
  labels:
    app: loki
    component: monitoring
    part-of: hcbs-revenue-management
spec:
  replicas: 1
  selector:
    matchLabels:
      app: loki
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: loki
        component: monitoring
        part-of: hcbs-revenue-management
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "3100"
    spec:
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      containers:
        - name: loki
          image: grafana/loki:2.8.2
          imagePullPolicy: IfNotPresent
          args:
            - "-config.file=/etc/loki/loki.yaml"
          ports:
            - name: http
              containerPort: 3100
              protocol: TCP
            - name: grpc
              containerPort: 9096
              protocol: TCP
          volumeMounts:
            - name: config
              mountPath: /etc/loki
            - name: data
              mountPath: /data
          readinessProbe:
            httpGet:
              path: /ready
              port: http
            initialDelaySeconds: 30
            timeoutSeconds: 1
          livenessProbe:
            httpGet:
              path: /ready
              port: http
            initialDelaySeconds: 45
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 200m
              memory: 256Mi
            limits:
              cpu: 1
              memory: 1Gi
      volumes:
        - name: config
          configMap:
            name: loki-config
        - name: data
          persistentVolumeClaim:
            claimName: loki-data
---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: monitoring
  labels:
    app: loki
    component: monitoring
    part-of: hcbs-revenue-management
spec:
  type: ClusterIP
  ports:
    - port: 3100
      targetPort: http
      protocol: TCP
      name: http
    - port: 9096
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app: loki
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: monitoring
  labels:
    app: promtail
    component: monitoring
    part-of: hcbs-revenue-management
spec:
  selector:
    matchLabels:
      app: promtail
  template:
    metadata:
      labels:
        app: promtail
        component: monitoring
        part-of: hcbs-revenue-management
    spec:
      serviceAccountName: promtail
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      containers:
        - name: promtail
          image: grafana/promtail:2.8.2
          imagePullPolicy: IfNotPresent
          args:
            - "-config.file=/etc/promtail/promtail.yaml"
          volumeMounts:
            - name: config
              mountPath: /etc/promtail
            - name: run
              mountPath: /run/promtail
            - name: pods
              mountPath: /var/log/pods
              readOnly: true
            - name: containers
              mountPath: /var/lib/docker/containers
              readOnly: true
          env:
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          ports:
            - containerPort: 9080
              name: http-metrics
          livenessProbe:
            httpGet:
              path: /ready
              port: http-metrics
            initialDelaySeconds: 10
            timeoutSeconds: 1
          readinessProbe:
            httpGet:
              path: /ready
              port: http-metrics
            initialDelaySeconds: 10
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 50m
              memory: 128Mi
            limits:
              cpu: 200m
              memory: 256Mi
      tolerations:
        - effect: NoSchedule
          operator: Exists
      volumes:
        - name: config
          configMap:
            name: promtail-config
        - name: run
          hostPath:
            path: /run/promtail
        - name: pods
          hostPath:
            path: /var/log/pods
        - name: containers
          hostPath:
            path: /var/lib/docker/containers
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: loki-data
  namespace: monitoring
  labels:
    app: loki
    component: monitoring
    part-of: hcbs-revenue-management
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: standard
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-rules
  namespace: monitoring
  labels:
    app: loki
    component: monitoring
    part-of: hcbs-revenue-management
data:
  alerts.yaml: |
    groups:
      - name: loki-alerts
        rules:
          - alert: HighErrorRate
            expr: sum(rate({app="hcbs-backend", level="error"}[5m])) by (namespace, app) > 0.1
            for: 5m
            labels:
              severity: critical
              category: application
            annotations:
              summary: "High error rate detected in {{ $labels.app }}"
              description: "Error rate exceeds 0.1 errors per second in {{ $labels.app }} in namespace {{ $labels.namespace }}"
              runbook_url: "https://runbooks.thinkcaring.com/application/high-error-rate"

          - alert: HighWarningRate
            expr: sum(rate({app="hcbs-backend", level="warn"}[15m])) by (namespace, app) > 0.5
            for: 15m
            labels:
              severity: warning
              category: application
            annotations:
              summary: "High warning rate detected in {{ $labels.app }}"
              description: "Warning rate exceeds 0.5 warnings per second in {{ $labels.app }} in namespace {{ $labels.namespace }}"
              runbook_url: "https://runbooks.thinkcaring.com/application/high-warning-rate"

          - alert: AuthenticationFailures
            expr: sum(rate({app="hcbs-backend", req_url=~"/api/auth/login|/api/auth/refresh", res_status=~"4.*"}[15m])) by (namespace, app) > 0.1
            for: 15m
            labels:
              severity: warning
              category: security
            annotations:
              summary: "Authentication failures detected"
              description: "High rate of authentication failures detected in application {{ $labels.app }}"
              runbook_url: "https://runbooks.thinkcaring.com/security/authentication-failures"

          - alert: ClaimProcessingErrors
            expr: sum(rate({app="hcbs-backend", logger="claims-service", level="error"}[15m])) by (namespace, app) > 0
            for: 15m
            labels:
              severity: high
              category: business
            annotations:
              summary: "Claim processing errors detected"
              description: "Errors detected in claims processing service"
              runbook_url: "https://runbooks.thinkcaring.com/business/claim-processing-errors"

          - alert: PaymentProcessingErrors
            expr: sum(rate({app="hcbs-backend", logger="payment-service", level="error"}[15m])) by (namespace, app) > 0
            for: 15m
            labels:
              severity: high
              category: business
            annotations:
              summary: "Payment processing errors detected"
              description: "Errors detected in payment processing service"
              runbook_url: "https://runbooks.thinkcaring.com/business/payment-processing-errors"

          - alert: APIServerError
            expr: sum(rate({app="hcbs-backend", res_status=~"5.*"}[5m])) by (namespace, app) > 0.1
            for: 5m
            labels:
              severity: critical
              category: application
            annotations:
              summary: "API server errors detected"
              description: "High rate of HTTP 5xx errors in {{ $labels.app }}"
              runbook_url: "https://runbooks.thinkcaring.com/application/api-server-errors"

  system-alert-rules.yaml: |
    groups:
      - name: loki-system-alerts
        rules:
          - alert: PodCrashLoopBackOff
            expr: sum by (namespace, pod) (rate({namespace=~"hcbs|monitoring", component="controller-manager", log=~".*Back-off restarting failed container.*"}[1h])) > 0
            for: 15m
            labels:
              severity: critical
              category: system
            annotations:
              summary: "Pod CrashLoopBackOff detected: {{ $labels.pod }}"
              description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is crash looping"
              runbook_url: "https://runbooks.thinkcaring.com/kubernetes/pod-crash-looping"

          - alert: KubernetesNodeProblems
            expr: sum by (namespace, node_name) (rate({app="node-exporter", log=~".*Error|.*Failed|.*Warning.*"}[1h])) > 0.1
            for: 30m
            labels:
              severity: high
              category: system
            annotations:
              summary: "Kubernetes node issues detected: {{ $labels.node_name }}"
              description: "Node {{ $labels.node_name }} is experiencing issues"
              runbook_url: "https://runbooks.thinkcaring.com/kubernetes/node-problems"

          - alert: DatabaseErrors
            expr: sum by (namespace, app) (rate({app="hcbs-backend", logger="database", level="error"}[15m])) > 0
            for: 15m
            labels:
              severity: high
              category: database
            annotations:
              summary: "Database errors detected in {{ $labels.app }}"
              description: "Database errors detected in application {{ $labels.app }}"
              runbook_url: "https://runbooks.thinkcaring.com/database/database-errors"

  security-alert-rules.yaml: |
    groups:
      - name: loki-security-alerts
        rules:
          - alert: BruteForceAttempt
            expr: sum by (namespace, app, pod_ip) (count_over_time({app="hcbs-backend", req_url="/api/auth/login", res_status=~"4.*"}[1h])) > 10
            labels:
              severity: critical
              category: security
            annotations:
              summary: "Possible brute force attempt detected from {{ $labels.pod_ip }}"
              description: "Multiple failed login attempts detected from the same source"
              runbook_url: "https://runbooks.thinkcaring.com/security/brute-force-attempt"

          - alert: UnauthorizedAccessAttempt
            expr: sum by (namespace, app, req_url) (rate({app="hcbs-backend", res_status="403"}[15m])) > 0.1
            for: 15m
            labels:
              severity: high
              category: security
            annotations:
              summary: "Unauthorized access attempts detected to {{ $labels.req_url }}"
              description: "Multiple unauthorized access attempts to protected resources"
              runbook_url: "https://runbooks.thinkcaring.com/security/unauthorized-access"

          - alert: SensitiveDataAccess
            expr: sum by (namespace, app, pod, user_id) (rate({app="hcbs-backend", logger=~"audit.*", log=~".*PII|.*PHI|.*sensitive"}[1h])) > 0.05
            for: 30m
            labels:
              severity: high
              category: security
            annotations:
              summary: "High rate of sensitive data access by user {{ $labels.user_id }}"
              description: "User {{ $labels.user_id }} is accessing sensitive data at an unusual rate"
              runbook_url: "https://runbooks.thinkcaring.com/security/sensitive-data-access"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: promtail
  namespace: monitoring
  labels:
    app: promtail
    component: monitoring
    part-of: hcbs-revenue-management
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: promtail
  labels:
    app: promtail
    component: monitoring
    part-of: hcbs-revenue-management
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - nodes/proxy
      - services
      - endpoints
      - pods
    verbs: ["get", "watch", "list"]
  - apiGroups: ["extensions"]
    resources:
      - ingresses
    verbs: ["get", "watch", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: promtail
  labels:
    app: promtail
    component: monitoring
    part-of: hcbs-revenue-management
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: promtail
subjects:
  - kind: ServiceAccount
    name: promtail
    namespace: monitoring